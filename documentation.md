# Project Documentation
## Sonic Thinking Seminar - Methods of Working with Sound, Summer Term 2021
Course offered by: Dr. Julia von Thienen

This document serves as a documentation for the seminar "Sonic Thinking Seminar - Methods of Working with Sound" at HPI.  
The content is structured as follows:  
[1.) Project title](#1-project-title)  
[2.) Team members, affiliations, contact details](#2-team-members-affiliations-contact-details)  
[3.) The project aim and why this is important](#3-the-project-aim-and-why-this-is-important)  
[4.) Theoretical embedding, related works](#4-theoretical-embedding-related-works)  
[5.) Methods](#5-methods)  
[6.) Work results](#6-work-results)  
[7.) Conclusion, discussion, limitations and avenues for future work](#7-conclusion-discussion-limitations-and-avenues-for-future-work)  
[8.) Acknowledgements](#8-acknowledgements)  
[Reference List](#reference-list)  

### 1.) Project title
Listen To Air Pollution

### 2.) Team members, affiliations, contact details
**Carla Terboven**  
carla.terboven@student.hpi.de  
IT-Systems Engineering

### 3.) The project aim and why this is important
Air pollution is generated by emissions from road traffic, power plants, furnaces or heaters in residential buildings, and many more sources [[2]](#air-pollution). Most air pollution is produced by human activity, even though it brings critical health and climate problems.  
When we breathe in polluted air, particles can get into our lungs and blood, leading to inflammation in the trachea, an increased tendency to thrombosis, or even changes nervous system like heart rate variability [[2]](#air-pollution).  
Particularly dangerous are the smallest particles in the air. They are grouped with the term *particulate matter (PM)* (german: "Feinstaub"). PM is a mixture of solid and liquid particles. Distinctions are made in the size of the particles, no matter what chemical elements are involved. More detailed information on PM is given in the [data preparation](#data-preparation) section.

Because it leads to health and climate problems, PM also gets more and more attention from artists. *Anirudh Sharma* motivates people all around the world to think differently about air pollution. He produces *Air Ink* out of PM2.5 particles [[1]](#air-pollution). Artists can use this rich, dark black ink for paintings or textile printing. With *Air Ink* air pollution is turned into something useful. Most artists use *Air Ink* to communicate health and climate problems caused by air pollution in their paintings. I believe that more and more people are aware of these problems. But when we ask ourselves how much particulate matter we breathe in when we go outside in our own neighborhood, we do not have a clue.  
Even though many city councils monitor air quality, the measuring stations are installed in fixed positions [[3]](#air-pollution). But how is the air pollution, right here and right now, in our neighborhood? How can I raise attention to our individual interaction with air and air pollution?  

In the Sonic Thinking class at May 17th, Marisol Jimenez introduced the sound sculpture *Woodworms* by Zimoun [[xxx]](#inspiration-and-vision). He placed 25 woodworms in a piece of wood and recorded them with an ultrasensitive microphone. The sound of the woodworms is made audible to the viewers with a sound system. I am fascinated by the idea to enable people to hear something that they normally cannot hear even though it is there already.  
With Zimoun's *Woodworms* as an inspiration in mind I was able to formulate a goal for my project: **“I want to enable people to hear what is around them in the air already. I want people to hear the air pollution around them.“**  
To do that, I firstly have to think about the sound of air pollution. Zimoun‘s woodworms produced a natural sound but what is the sound of air pollution? I still discover this question and decided to use different samples that people can directly connect to air pollution or the absence of air pollution. Most samples are self recorded and some are taken from https://freesound.org/.  
Another strength of Zimoun's sculpture is the great picture it creates. Placing a microphone next to the piece of wood directly communicates what is recorded. I wonder how I can create a picture like that. How can I communicate that I sonify air pollution? I could, for example, design the device with the air pollution sensor in a figurative way.

Regarding the project outcome of the seminar project, I am interested in translating data to sound that the user can intuitively understand. This semester I try to do that based on recorded samples with a sound connected to air pollution.  
I aim to raise awareness of air pollution in individual environments. Towards the end of the semester, I envision to create a transportable device with a sensor. While walking, the sensor measures the particulate matter, and this live data is directly sonified and presented to the user via headphones.

<!-- 2) Introduction to the topic: basically ☺, please ensure a good consistency between your communicated project aims and the chosen sound design / sonification approach
2a) The aim of your project, and why it is important/interesting: Generally ☺, please re-adjust or amend based on your preferred methodology and solutions -->

### 4.) Theoretical embedding, related works
As explained in the last section, I decided to sonify air pollution data. Since there are several possibilities of sonifications out there, I introduce some theoretical sonification approaches in the beginning. After that, I present different sonification projects around the topic of air pollution. Some of these projects serve as a source of inspiration for my own project.

#### Sonification
Sonification is defined as "the transformation of data relations into perceived relations in an acoustic signal for the purposes of facilitating communication of interpretation" [[7]](#sonification-1).   
But why is it interesting for me to inform people about air pollution data via acoustic audio signals instead of using visual plots, as most people are used to consume scientific data via plots and tables? The users of my device should be able to explore their neighborhood or parts of the city while using the device. Knowing that they walk around with visual focus on their surroundings and they might concentrate on traffic, I have to communicate the data in an intuitive, not too distracting way. Still, I want to achieve an understanding and awareness of the existing air pollution.    

Paul Vickers describes in chapter 18 of "The Sonification Handbook" three different modes of monitoring: *direct, peripheral, and serendipitous-peripheral* [[11]](#sonification-1). When monitoring information in a direct way, the main focus of attention is claimed. For peripheral monitoring, the "attention is focused on a primary task whilst required information relating to another task or goal is presented on a peripheral display and is monitored indirectly" [[11]](#sonification-1). And the "attention is focused on a primary task whilst information that is useful but not required is presented on a peripheral display and is monitored indirectly" [[11]](#sonification-1) when using serendipitous-peripheral monitoring. I aim to monitor air pollution data while the users explore the city. The users should not walk only heads-down with the eyes on a display. But concentrate on the surroundings like nature or traffic. So I do not want to present air pollution data in an attention-grabbing way. This means that I aim to deliver the data in a peripheral or serendipitous-peripheral way. Since the "human auditory system does not need a directional fix on a sound source in order to perceive its presence" [[11]](#sonification-1), monitoring with audio seems to be a perfect way.  

But how can the user intuitively understand the monitored data? Rauterberg and Styger [[9]](#sonification-1) advise to "look for everyday sounds that 'stand for themselves'". And Tractinsky et al. [[10]](#sonification-1) state that user perception is driven by aesthetics and there is growing evidence that there is an increased usability of systems designed with an aesthetic focus.
According to Vickers [[11]](#sonification-1), "the embedding of signal sounds inside some carrier sound" also leads to user satisfaction because of less annoyance and distraction. Vickers introduces approaches where user-selected music serves as the carrier sound of the sonification signals. It might be an exciting thing to look at, since a lot of people walk around with headphones on, listening to music already.  
But apart from the aesthetic, user-centered everyday sound, I also found more theoretical design concepts for sonification.  
Kramer [[6]](#sonification-1) makes a distinction between *analogic and symbolic representations* of the data. An example of analogic representation is the Geiger counter because it directly maps data points to sound. The listener can understand the immediate one-to-one connection between data and sound signals. This is different for a symbolic representation. Here the data only gets represented categorically, and there is no direct relationship between data and relationship necessary. Examples are most control notifications in cars. To me, the analogic representation sounds interesting because it can directly transport a lot of the data's meaning. Moreover, the sound of the Geiger counter could communicate the association of poisoned air to the user. A notification-like sound might be interesting when passing certain air pollution thresholds of the EU or WHO. I can imagine a symbolic representation at that point.  
Another concept are semiotic distinctions. Here one can differentiate *syntactic methods* using, e.g., earcons, *semantic methods* like auditory icons, and *lexical methods* as parameter mapping [[4]](#sonification-1).   
Earcons are a very abstract representation of the data what makes them hard to understand. Because I want the user to understand the data quite intuitively, I now take a closer look at semantic and lexical methods.  
Semantic methods like auditory icons map data to everyday sound. This leads to familiarity and quick understanding as well as direct classification options. But the mapping of data to auditory icons is complicated, especially because one have to think about a good representation for air pollution data that does not have a natural physical sound.  
When using parameter mapping, different data dimensions are mapped to acoustic properties like pitch, duration, or loudness. This way, one can listen to multiple data dimensions simultaneously and create a complex sound. But it is pretty challenging to balance everything in a way that the listener can still pick up the meaning of the data [[4]](#sonification-1). Moreover, it becomes unpleasant quite fast, and one have to balance the alarming content of air pollution and the confidence and well-being of the user. Last semester, Malte Barth and I concentrated on such a musical approach with parameter mapping for air pollution data. Since the resulting sound was hardly intuitive I concentrate on other approaches this semester.  
Thinking more closely about the continuous stream of air pollution data I want to sonify, I hope to find different air pollution levels in Potsdam. Then I do not need attention-grabbing sounds all the time but can think about using them only in situations where the pollution data gets alarmingly high. Looking at specific design recommendations in the literature, McGee advises keeping sound events as short as possible and the spacing between sounds reasonable to avoid interference and sound masking as well as preventing the user from being overwhelmed by too many sound events [[8]](#sonification-1).

#### Sonification of air pollution data
Apart from general sonification approaches, I also took a look at past projects that communicated air pollution data with sound.  
Particularly interesting, I find a project by Marc St Pierre and Milena Droumeva [[18]](#sonification-of-air-pollution-data-1). They scale and map pollutants (CO, O3, SO2, and NO2) to individual frequencies using SuperCollider. The sound produced by these pollutants is already very telling, and it is possible to understand which pollutant is changing at any time once the listener knows the mapping. The sound is quite powerful and vibrant but becomes even more telling and interesting because of a Geiger counter/clicking sound that is somehow completing and competing with the rich sound of the other pollutants. The Geiger counter is based on PM2.5 data, which is "measured  differently  than  the other  chemicals  and  therefore  receives  a  different  mapping".  
Listening to their work on soundcloud (https://soundcloud.com/marcstpierre retrieved 2021-03-16), I am fascinated by how the Geiger counter sounds interesting for a long time even though the clicking sound itself does not change in pitch but only in rhythm. I imagine this is caused by the mysterious sound patterns that are produced by the other pollutants. The combination of vibrant, rich sound and the clicking Geiger counter is fascinating.

Julián Jaramillo Arango introduces a paper about AirQ Sonification [[12]](#sonification-of-air-pollution-data-1). It combines three different projects, all concerned with air pollution in 2016 and 2017.  They are called *AirQ Jacket*, *Esmog Data*, and *Breathe!*.   
"*AirQ Jacket* is a piece of clothing with an attached electronic circuit, which measures contamination levels and temperature and transforms this information to visual and acoustic stimuli" [[12]](#sonification-of-air-pollution-data-1). It is using multiple sensors to collect the data and small lightweight speakers and LEDs to communicate the data to the user. The designers imagined "to create healthy courses through the city" [[12]](#sonification-of-air-pollution-data-1) with these jackets. The white jacket perhaps attracted a lot of attention but looks a bit too alien-like to me. Air pollution is happening all around us so I am exited about communicating my project with a small sensor kit and 'normal' headphones.  
*Esmog Data* is an art installation using audio and motion graphics to achieve a "meaningful listening experience" [[12]](#sonification-of-air-pollution-data-1). Each collected sensor data point (CO, CO2, SO2, and PM10) is therefore connected to multiple parameters of the synthesizer to generate "more  complex  musical  values" [[12]](#sonification-of-air-pollution-data-1).   
"*BREATHE!* is a multi-channel installation with no visuals, where the visitor should be able to identify each one of the measured toxic gases as a different sound source in the space. [...] The  installation  displays  six  human  breathing  sound  loops,  which  shrink  and  stretch from different points in the space according to toxic levels." [[12]](#sonification-of-air-pollution-data-1) Interestingly, the artists considered the breathing as some kind of communication that people can understand all over the world. We all breathe the same. I would love to achieve this intuitive communication of the data for my project, not necessarily with breathing sound but with a collection of own samples.

Next to these scientific papers, I also found exciting sound examples online. For instance *Space F!ght* in collaboration with the *Stockholm Environment Institute* and *NASA's Goddard Institute for Space Studies* want to communicate the level of ozone data through art [[14]](#sonification-of-air-pollution-data-1). They perform a combination of parameter marking, speech, and improvisation of a trumpet player. I find the sound quite mystic as well as concerning and alarming. The improvising trumped is guided by the Ozon data and gives a sensitive touch to the performance. The group states that they chose to work with ozone data because ozone is proved to directly affect climate, and human health.

The auditory display by Kasper Fangel Skov [[17]](#sonification-of-air-pollution-data-1) is concerned about climate and human health as well but focuses not on ozone but on dimensions like temperature, light, humidity, and noise. Interestingly this auditory display of urban environmental data of different cities also uses voice to classify the used data in categories like "high" or "medium".

Also interesting is a project by Jon Bellona and John Park [[13]](#sonification-of-air-pollution-data-1) [[16]](#sonification-of-air-pollution-data-1). They are not directly sonifying air pollution data but carbon emissions of twitter feeds. This indirect concern about air pollution is communicated with a physical visualization. The auditive, as well as visual experience, aims to connect virtuality and reality. Based on the estimation that one twitter tweet produces 0.02 grams of CO2, gas bubbles inside a water tank are released based on personal twitter feed data. The usage of gas bubbles in water creates a strong picture, that I find comparable to the microphone recording the wood in Zimoun's *Woodworms* sound sculpture[[xxx]](#inspiration-and-vision). Moreover, the physical visualization is supported by sound, making the feeling transported by the installation even more powerful.

Apart from the sonification projects described above, I got inspiration by the *Sonic Kayak* [[15]](#sonification-of-air-pollution-data-1) and the *Sonic Bike* [[19]](#sonic-bikes) [[20]](#sonic-bikes) [[21]](#sonic-bikes) projects. Both projects were introduced to me by *Kaffe Matthews* who works on these topics for some years.  
The *Sonic Kayak* project generates live sound on the kayak, using sensors in the water as well as sensors for air particulate pollution, GPS, and time.  
Also concerned about air particulate pollution is the *Sonic Bike* project. Here, an air pollution sensor with 12 channels gathers live data on a bike. The data is then processed at the back of the bike, using Raspberry Pi and PD vanilla. Finally, the bike rider can experience the sonified air pollution via two speakers attached to the bicycle handlebar and a subwoofer behind the bike seat.    
Initially, I started with Malte Barth, working on an interpretation of the *Sonic Bike* project. But due to the COVID-19 pandemic, we decided to use recorded CSV data instead of the bikes with live data. I now want to overcome this barrier with a self-made small device that can be used with headphones while walking. I believe that this setup might even allow for a closer inspection of the own neighborhood since a biker explores the surroundings much faster than a pedestrian. During a walk the air can possibly be experienced more precisely and directly.

The original *Sonic Bike* project directly deals with the data in PD vanilla. I decided to use the programming language python as much as I can. So I collect the sensor data, and compute most steps based on this data in python. Only the final commands which play the samples are sended to PD (*Pure Data*). This way I want to play my strength in programming skills and overcome the lack of experience with PD. A more detailed overview of my current approach can be found in the next section.

### 5.) Methods
On the way from the pure air particulate pollution to a meaningful sonification, I had to overcome multiple challenges.  
One challenge is of course to manage all the hardware parts to work together. On software side I had to read and preprocess the data. Depending on the data, using different particle sizes, I compute various parameters to generate a telling sound. Finally, I use OSC (*Open Sound Control*) to send the processed information to PD. Here I read the messages to control the speed and time of recorded samples.  
In the following sections, I take a more detailed look into each step I take to hear the sonified data in the end successfully.

<!-- 3) Methods used: Beginning 😊. It will be interesting to see what sonification methods you decide on in the end. I also recommend adding one slide in your presentation where you spell out a study design how your tool could be tested practically. E.g., you could test different sonification approaches and ask people via a questionnaire how they experienced each sonification (pleasant, informative, annoying…). In that case, it would be good to have a list of questions that would want to ask. Since you are only one person, enrolled in only one class, it is not necessary that you add empirical tests of your approach in the final submission (while empirical tests generally make up an important phase in any creative process). In terms of slides/project documentation, a study design belongs to the method section, but since in this case it will more likely be a method proposition for future works, you could also include it in the end of the slide presentation. (Because study design is intricate, I recommend sharing the slide/design prior to the final submission, if you like.)  -->

#### Hardware setup
To build a transportable device that enables users to listen to air pollution, multiple components are connected. I use a PLANTOWER PMS5003 sensor (http://www.plantower.com/en/content/?108.html) to gather the data, a Raspberry Pi 2 to process the data, and headphones to listen to the sonification. Moreover, for a transportable design of the device, I use a rechargeable battery pack to power the Raspberry Pi, and a transparent plastic box for protection of the electronic devices.

The rechargeable battery pack as well as the headphones are easily connected to the Raspberry Pi's corresponding plugs. To wire the sensor the Raspberry Pi's GPIO pins are used. According to the [sensor's documentation](https://www.distrelec.de/Web/Downloads/_t/ds/3686_eng_tds.pdf) three pins are required to read the data on sensor side: PIN1 (VCC) and PIN2 (GND) for 5V power and ground, and PIN5 (TX) is the serial port sending pin. These three pins are connected to the corresponding pins at the Raspberry Pi. Sensor PIN1 is wired to the Raspberry Pi's 5V pin, sensor PIN2 to the Raspberry Pi's ground and sensor PIN5 is connected to the Raspberry Pi's GPIO 15 (UART RX). A picture of the complete wiring is shown below. To finally read the data on software side I use the python package *pms5003-python* available on [GitHub](https://github.com/pimoroni/pms5003-python).

![Raspberry Pi Wiring]()

Apart from pure transportation and protection purposes I chose the transparent plastic box also for illustration reasons.
create picture
* box is completely transparent, as is the air that is sonified
* air pollution is human made, handwritten title, not completely polished wiring

Looks handmade
Decided to leave it like that on purpose
Not pollished as a lot of results in official spots are (Quelle?)
Human Made design
Transparency without hiding unangenehme oder unschöne Details

use in life
* size around 18cm x 16cm x 10cm

![Final Prototype Annotated]()
![Final Prototype Top View]()

#### Data Preparation
Last semester I worked on gathered PM data from Berlin that was kindly shared with me by *Kaffe Matthews*. The data consists of seven data sets measured in slightly different weather conditions. The following figure shows raincloud violin plots with the distribution of the PM values for all seven data sets.

![PM Raincloud Plots](https://raw.githubusercontent.com/malte-b/musical_env_bike/readme_images/readme_images/pm_raincloud.png)

The plot shows that the distribution of PM2.5 and PM10 nearly seems to be the same. This can be explained by the definition of PM ("Particulate Matter").
PM1 describes the amount of µg/m³ of particles smaller than 1 µm. PM2.5 includes the amount of µg/m³ of particles	smaller than 2.5 µm. And PM10 contains the amount of µg/m³ of particles	smaller than 10 µm. All particles that are smaller than 1 µm or 2.5 µm are smaller than 10 µm as well. If there are only a few particles with a size between 2.5 and 10 µm, the PM10 values equal the PM2.5 values most of the time.

For sonification, I want to use the PM data to manipulate different aspects of the auditory representation. If PM2.5 and PM10 values behave the same most of the time, the sound representation hardly becomes exciting and meaningful to the listener. This is why I decided to subtract the smaller PM values of the bigger ones for each live data point I read with the sensor. I call the generated values "disjoint PM". For the example data from last semester, the following plot proves that the distribution of the PM values becomes more distinct for the "disjoint PM".

![Disjoint PM Raincloud Plots](https://raw.githubusercontent.com/malte-b/musical_env_bike/readme_images/readme_images/disjoint_pm_raincloud.png)

Still, I have to keep in mind that I have to use the original PM data when comparing it to legal thresholds. There are statutory thresholds by the EU and more strict recommendations by the WHO to ensure human health. All average limits per year are presented in the following table (thresholds according to [[2]](#air-pollution)):

|          | PM 1     | PM 2.5   | PM 10    |
| -------- | -------- | -------- | -------- |
| EU       | -        | 25 µg/m³ | 40 µg/m³ |
| WHO      | -        | 10 µg/m³ | 20 µg/m³ |

#### PD Patch
To finally hear the sonified data, I use PD (*Pure Data*). I send the preprocessed information to PD via OSC (*Open Sound Control*). OSC is a network protocol mainly used for real-time processing of sound data. Having a background in computer science, I was able to set up the OSC client on the python side quite fast but needed support for the PD side. The tutorials by von Coler [[24]](#pd-examples) and Davison [[25]](#pd-examples) helped out so that messages with the preprocessed data can be used inside our PD patch.  
These messages trigger PD to play prerecorded samples at a certain speed. The setup is based on tutorials by Kreidler [[26]](#pd-examples) and Brown [[23]](#pd-examples). I hoped to create an intuitive understanding with samples that sound like air pollution. But since air pollution has no natural sound I tried multiple approaches using different samples.  

// traffic or engine exhaust, breathing, coughing, wind, bubble balks, doctor's stethoscope, and brass instruments. When thinking of sounds of measuring devices that measure hazardous substances in the air, I thought about Geiger counters and smoke detectors.  
// TODO nach we und our suchen und durch I and my ersetzen
// TODO quellen nummern überarbeiten

#### Idea 1: Breathing and Geiger Counter

#### Idea 2: Breathing and Air Bubbles

#### Idea 3: Traffic Noise

#### Idea 4: Bees and Birds

#### Idea 5: Music and Distortion

#### Study Design To Compare

### 6.) Work results
<!-- 4) Work results: creative outcome, e.g. demo, installation, code: Great that you had a well-functioning prototype and were able to share this in class! -->

#### Where to find the code and demo/prototypical application
Code: https://github.com/carlaterboven/listen_to_air_pollution  
Demos: https://github.com/carlaterboven/listen_to_air_pollution/tree/main/demos

### 7.) Conclusion, discussion, limitations and avenues for future work
<!-- 5) Conclusion and discussion, including limitations of your work and potential avenues for future work: Please work this out in detail. There should be a headline “conclusions” re-stating your overarching aims/vision and reviewing how far you have come with this; there should be a headline “limitations” followed by a couple of bullet points with the limitations you currently acknowledge, suggesting next likely steps to follow. Compare your slide 11 to slide 4. Your next step is to use more than one channel. Why? Which of your three goals on slide 11 is not fully met as of yet? Why would creating more channels be a helpful means to better achieving this particular goal? -->
### Conclusion
// TODO überarbeiten
Our goal of this project was to make people more aware of the air pollution in their daily life by sonifying real-time air pollution data on a bike. Simultaneously we used musical foundations for generating sounds to make differences of pollution more noticeable for a layman by sounding less and less pleasant the higher the pollution gets.
We think that we have come quite far with our work considering we did not re-use any existing code of the *Sonic Bike* project but instead wrote all the logic behind our sound generation from scratch in Python and also wrote the necessary PD patches to get the sounds we envisioned without any prior experience with it.

Sadly, courtesy of the ongoing pandemic and lockdown measures, we were unable to make our solution work on an actual sonic bike with real-time data but had to rely on recorded rides instead. This functionality would be the first step in making our vision of cyclists hearing the air pollution around them a reality. The user feedback that would surely arise from those rides would certainly help us to make the experience even better.

### Limitations
// TODO überarbeiten
Right now, the chords do not take into account which notes were played before them. Adding a memory of what was played before might help our sounds to become even more musical and help smoothen out transitions. This can be done using machine learning techniques, for example.

Furthermore, in one time interval, there is only the same chord played repeatedly. This can be changed by either playing less notes as it may become annoying over time or by playing a melody over a static chord. Also, there is always the same meter being 4/4, which could be changed and therefore given a different experience.

Another interesting consideration for the future could be interactive sonification. Herman and Hunt [[5]](#sonification-1) state that most sonification "fails to engage users in the same way as musical instruments" because they lack physical interaction and naturalness. The usage of naturalness of sound in the real world already got our attention when thinking about an intuitive way of monitoring air pollution. But thinking of sonification with physical interaction possibilities would be a new level.
For our sonification, we map multiple dimensions of data to acoustic properties. Herman and Hunt recommend including interactive controls and input devices in this mapping.
For example, the cyclist could choose the sound of the most alarming data points to be a Geiger counter, smoke detector sound, or heavy breathing. Maybe the preferences even change when being in different locations of the city. We imagine interactive customization of the sonification would increase user satisfaction and usage and maybe consolidate personal associations with air pollution.


### 8.) Acknowledgements
I would like to thank Sven Köhler for his input on other air pollution projects and sensors. His shared literature was of great help when setting up the sensor.
Moreover, I thank Malte Barth for his support last semester when we did our first steps with the sonification of air pollution data together. During that time Kaffe Matthews and Henrik von Coler shared their help and expertise with us. Thank you for providing test data, sharing ideas and helping to set up the technical framework.

### Reference List
#### Air Pollution
[[1]](https://www.ted.com/talks/anirudh_sharma_ink_made_of_air_pollution) Anirudh Sharma, TED@BCG Toronto (2018). *Ink made of air pollution.* Retrieved from https://www.ted.com/talks/anirudh_sharma_ink_made_of_air_pollution on 2021-03-27  
[[2]](https://www.umweltbundesamt.de/themen/luft/luftschadstoffe-im-ueberblick/feinstaub) Umweltbundesamt (2021). *Feinstaub.* Retrieved from https://www.umweltbundesamt.de/themen/luft/luftschadstoffe-im-ueberblick/feinstaub on 2021-03-27  
[[3]](https://aqicn.org/here/de/) World Air Quality Index Team (started in 2008). *The World Air Quality Project: Echtzeit-Luftqualitätsindex (LQI).* Retrieved from https://https://aqicn.org/here/de/ on 2021-03-27  

#### Inspiration and Vision
[[xxx]](https://www.zimoun.net/sculptures/) Zimoun (2009). *Woodworms.* Retrieved from https://www.zimoun.net/sculptures/ and https://vimeo.com/14424815 on 2021-08-23

#### Sonification  
[[4]](
https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.6715&rep=rep1&type=pdf
) Barrass, S., & Kramer, G. (1999). *Using sonification.* Multimedia systems, 7(1), 23-31.   
[[5]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1423929) Hermann, T., & Hunt, A. (2005). *Guest editors' introduction: An introduction to interactive sonification.* IEEE multimedia, 12(2), 20-24.  
[[6]](#sonification-1) Kramer, G. (1994). *Auditory Display: Sonification, Audification and Auditory Interfaces.* SFI Studies in the Sciences of Complexity, Proceedings Volume XVIII. Addison Wesley, Reading, Mass.  
[[7]](https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1443&context=psychfacpub) Kramer, G., Walker, B. N., Bonebright, T., Cook, P., Flowers, J., Miner, N., et al. (1999). *The Sonification Report: Status of the Field and Research Agenda.* Report prepared for the National Science Foundation by members of the International Community for Auditory Display. Santa Fe, NM: International Community for Auditory Display (ICAD)  
[[8]](https://lifeorange.com/writing/Sonification_Auditory_Display.pdf) McGee, R. (2009). *Auditory displays and sonification: Introduction and overview.* University of California, Santa Barbara.  
[[9]](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.9276&rep=rep1&type=pdf) Rauterberg, M., & Styger, E. (1994). *Positive effects of sound feedback during the operation of a plant simulator.* In International Conference on Human-Computer Interaction (pp. 35-44). Springer, Berlin, Heidelberg.  
[[10]](http://usd-apps.usd.edu/coglab/schieber/hedonomics/pdf/Tractinsky2000.pdf) Tractinsky, N., Katz, A. S., & Ikar, D. (2000). *What is beautiful is usable.* Interacting with computers, 13(2), 127-145.  
[[11]](https://sonification.de/handbook/download/TheSonificationHandbook-chapter18.pdf) Vickers, P. (2011). *Sonification for process monitoring.* In The sonification handbook (pp. 455-492). Logos Verlag.  


#### Sonification of air pollution data  
[[12]](https://www.revistas.ufg.br/musica/article/download/53573/25694/) Arango, J. J. (2018). *AirQ Sonification as a context for mutual contribution between Science and Music.* Revista Música Hodie, 18(1).  
[[13]](https://carbonfeed.org/) Bellona, J & John Park, J & Bellona, D. (2014). *#Carbonfeed, About.* Retrieved from https://carbonfeed.org/ on 2021-03-16  
[[14]](https://cdm.link/2013/11/sci-fi-electronic-band-music-made-ozone-data-elektron-drum-machine-sonification/) cdm (2013). *A Sci-Fi Band and Music Made from Ozone Data: Elektron Drum Machine, Sax Sonification.* Retrieved from https://cdm.link/2013/11/sci-fi-electronic-band-music-made-ozone-data-elektron-drum-machine-sonification/ on 2021-03-16  
[[15]](https://fo.am/activities/kayaks/) FoAM (2020). *Sonic Kayaks.* Retrieved from https://fo.am/activities/kayaks/ on 2021-03-16  
[[16]](https://vimeo.com/109211210) Harmonic Laboratory (2014). *#CarbonFeed - The Weight of Digital Behavior.* Retrieved from https://vimeo.com/109211210 on 2021-03-16  
[[17]](https://soundcloud.com/kasper-skov/sonification-excerpt-4-rio-de) Kasper Fangel Skov (2015). *Sonification excerpt #4: Rio de Janeiro.* Retrieved from https://soundcloud.com/kasper-skov/sonification-excerpt-4-rio-de on 2021-03-16  
[[18]](https://smartech.gatech.edu/bitstream/handle/1853/56580/ICAD2016_paper_33.pdf?sequence=1&isAllowed=y) St Pierre, M., & Droumeva, M. (2016). *Sonifying for public engagement: A context-based model for sonifying air pollution data. International Community on Auditory Display.* (sound files: https://soundcloud.com/marcstpierre retrieved 2021-03-16)  


#### Sonic Bikes  
[[19]](https://sonicbikes.net/environmental-bike-2020/) Bicrophonic Research Institute (2020). *Environmental Bike (2020).* Retrieved from https://sonicbikes.net/environmental-bike-2020/ on 2021-03-16  
[[20]](https://www.kaffematthews.net/project/environmental-bike-2020) Kaffe Matthews (2020). *Environmental Bike (2020).* Retrieved from https://www.kaffematthews.net/project/environmental-bike-2020 on 2021-03-16  
[[21]](https://www.kaffematthews.net/category/Lisbon/) Kaffe Matthews (2020). *Sukandar connects the air pollution sensor / Environmental Bike gets real.* Retrieved from https://www.kaffematthews.net/category/Lisbon/ on 2021-03-16  

#### Methods
// TODO überarbeiten, 22 entfernt

#### PD examples  
[[23]](https://www.youtube.com/watch?v=br7Hcx_FLoc) QCGInteractiveMusic/Andrew R. Brown (2020). *39. Modifying Audio File Playback with Pure Data.* Real-time Music and Sound with Pure Data vanilla. Retrieved from https://www.youtube.com/watch?v=br7Hcx_FLoc on 2021-03-28  
[[24]](https://hvc.berlin/puredata/) Henrik von Coler (2020). *Puredata.* Retrieved from https://hvc.berlin/puredata/ on 2021-03-16   
[[25]](https://archive.flossmanuals.net/pure-data/network-data/osc.html) Patrick Davison (2009). *Open Sound Control (OSC).* Retrieved from https://archive.flossmanuals.net/pure-data/network-data/osc.html on 2021-03-16   
[[26]](http://www.pd-tutorial.com/german/ch03.html) Johannes Kreidler (2009). *Programmierung Elektronischer Musik in Pd.* Kapitel 3. Audio. Retrieved from http://www.pd-tutorial.com/german/ch03.html on 2021-03-16   
